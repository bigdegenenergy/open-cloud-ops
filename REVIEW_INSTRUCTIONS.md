# ⚠️ REVIEW INSTRUCTIONS

> Generated by Gemini

```json
{
  "review": {
    "summary": "The PR introduces a massive and well-structured polyglot codebase. However, there are critical security and reliability issues: potential OOM during backup encryption, silent data loss in the LLM gateway logging, and high-risk automated shell command approval in the .claude toolkit. Database migration strategies are also missing.",
    "decision": "REQUEST_CHANGES"
  },
  "issues": [
    {
      "id": 1,
      "severity": "critical",
      "file": "aegis/internal/backup/manager.go",
      "line": 0,
      "title": "Memory Exhaustion (OOM) in Backup Encryption",
      "description": "The encryptFile function (described in chunk 1) uses os.ReadFile to load the entire backup archive into memory before applying AES-GCM encryption. For Kubernetes backups containing large volumes or many resources, this will lead to immediate OOM kills on the container.",
      "suggestion": "Implement streaming encryption using a cipher.StreamReader/StreamWriter or process the file in chunks (e.g., 32KB) using io.Copy to an encrypted destination."
    },
    {
      "id": 2,
      "severity": "critical",
      "file": "cerebra/internal/proxy/handler.go",
      "line": 0,
      "title": "Silent Financial Data Loss in Proxy Logging",
      "description": "The ProxyHandler uses a buffered channel of size 4096 for usage logs. The implementation drops logs when the channel is full. Since Cerebra is a FinOps gateway, dropping these logs results in permanent loss of cost and usage telemetry, rendering the budget enforcement and analytics inaccurate.",
      "suggestion": "Instead of dropping logs, implement a blocking write or, preferably, spill to a local persistent buffer/WAL (Write Ahead Log) or use a reliable messaging system (like Redis Streams) as the intermediary."
    },
    {
      "id": 3,
      "severity": "important",
      "file": "economist/pkg/cloud/gcp.py",
      "line": 0,
      "title": "Potential SQL Injection in BigQuery Queries",
      "description": "The get_costs method interpolates the project ID directly into the BigQuery query string using f-strings (FROM `{self._settings.gcp_project_id}...`). If the project ID configuration is sourced from an external or compromised setting, it allows for query manipulation.",
      "suggestion": "Use BigQuery parameterized queries for all dynamic values, or strictly validate that the project_id matches an expected alphanumeric/hyphen pattern before interpolation."
    },
    {
      "id": 4,
      "severity": "important",
      "file": ".claude/hooks/auto-approve.sh",
      "line": 0,
      "title": "Security Risk in Automated Command Approval",
      "description": "The hook uses a whitelist and a basic regex to prevent shell metacharacters. Regex-based shell sanitization is notoriously fragile and can often be bypassed with various encoding or shell-specific character interpretations, potentially allowing an AI agent to execute arbitrary code if manipulated by prompt injection.",
      "suggestion": "Remove automatic approval for high-risk commands or use a robust containerized sandbox (like gVisor or Docker) for the agent's execution environment where permissions are enforced at the kernel/system level rather than via regex filters."
    },
    {
      "id": 5,
      "severity": "important",
      "file": "aegis/api/handlers.go",
      "line": 0,
      "title": "Insecure Direct Object Reference (IDOR) in Backup API",
      "description": "The Aegis handlers extract an entity_id during authentication but do not pass this context into the manager methods (e.g., GetBackup, DeleteBackup). This allows any user with a valid API key to access or delete backups belonging to other entities simply by knowing the backup ID.",
      "suggestion": "Update the manager interfaces to accept entity_id as a parameter and include it in the WHERE clause of all database queries or filtering logic."
    },
    {
      "id": 6,
      "severity": "suggestion",
      "file": "cerebra/pkg/database/database.go",
      "line": 0,
      "title": "Lack of Database Migration Strategy",
      "description": "The services use 'CREATE TABLE IF NOT EXISTS' during application startup. This makes schema evolution (adding columns, changing types, adding indexes) extremely difficult and error-prone in production environments.",
      "suggestion": "Integrate a migration tool like 'golang-migrate' for Go and 'Alembic' for the Python Economist module."
    },
    {
      "id": 7,
      "severity": "important",
      "file": "economist/pkg/cost/calculator.py",
      "line": 0,
      "title": "Inaccurate Financial Aggregation with Static Exchange Rates",
      "description": "Currency normalization relies on a static internal table. Cloud costs fluctuate daily based on exchange rates; using hardcoded values will lead to significant discrepancies in consolidated monthly reports.",
      "suggestion": "Implement a caching layer that fetches daily exchange rates from a reliable financial API (e.g., Fixer.io or Open Exchange Rates)."
    }
  ]
}
```